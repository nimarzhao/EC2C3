\chapter{Endogeneity}

    To ensure unbiasedness of OLS estimator, or at least consistency of the OLS estimator we need to have \textit{exogeneity} of the errors, that is
    \begin{align}
        \cov{x,u} = 0
    \end{align}
    The failure of this assumption is called \textit{endogeneity}. Endogeneity can arise for a number of reasons:
    \begin{itemize}
        \item omitted variables
        \item lagged $y$ in the presence of autocorrelation in the error term
        \item simultaneity
        \item measurement errors
    \end{itemize}
    In this chapter we discuss how endogeneity can arise, and several strategies to overcome this.

    \section{Instrumental Variables (IV)}
        
        \subsection{Motivation}

            Suppose we have the following bivariate linear regression model:
            \begin{align}
                y = \beta_0 + \beta_1 x + u
            \end{align}
            If we have endogeneity, i.e. $\cov{x,u} = 0$, then our OLS estimates will be in general, biased. The approach of the previous chapters was to ensure the confounders were appropriately controlled for, and hope $x$ is no longer endogenous. In this section, we introduce another method; through the use of an \textit{instrumental variable} to deal with the endogenous regressor.
            \begin{figure}
                \centering
                \input{figures/IV}
                \caption{Mechanism behind IV}
                \label{fig:IV}
            \end{figure}

            \begin{definition}[IV]
                A valid \textit{instrumental variable}, $z_i$ satisfies two conditions
                \begin{enumerate}
                    \item $z$ is \textbf{exogenous} to the equation, i.e. 
                    \begin{align}
                        \cov{z,u} = 0
                    \end{align}
                    \item $z$ is \textbf{relevant} for explaining $x$, i.e.
                    \begin{align}
                        \cov{z,x} = 0
                    \end{align}
                \end{enumerate}
            \end{definition}

        \subsection{Estimator derivation}
            \begin{theorem}
                If $z$ is an instrumental variable, then $\beta$ can be recovered through
                \begin{align}
                    \beta = \frac{\cov{z,y}}{\cov{z,x}}
                \end{align}
            \end{theorem}
            \begin{proof}
                We have that
                \begin{align}
                    \operatorname{cov}(z,y)= \operatorname{cov}(z,\beta_0 +\beta_1 x +u ) = \beta_1\operatorname{cov}(z, x)
                \end{align}
                Rearrange to yield the result.
            \end{proof}
            \begin{definition}[IV estimator]
                The IV estimator is the MM estimator of $\beta$,
                \begin{align}
                    \hat\beta^\mathrm{IV}_1 = \frac{\ecov{z,y}}{\ecov{z,x}}
                \end{align}
            \end{definition}
            Why is such an instrument beneficial for estimating $\beta_1$? As we know $x$ could be endogenous, this means it is correlated with unknown confounders, as shown in Figure \ref{fig:IV}, and so OLS will produce biased estimates. A valid instrument will allow us to isolate the variation in  uncorrelated with confounders, we call $\hat x_i$, and estimate the effect of $\hat x_i$ on $y_i$, defined as $\hat\beta^\mathrm{IV}_1$ which is a consistent estimate of $\beta_1$ (although it turns out not unbiased).

        \subsection{Wald estimator}\label{def:endogeneity/Wald}
            \begin{definition}
                The \textit{Wald estimator} is defined as
                \begin{align*}
                    \hat\beta_1^\mathrm{Wald} := \frac{\hat\pi_1}{\hat \delta_1}
                \end{align*}
                where $\hat\delta_j$ are the \textit{first stage} regression coefficients,
                \begin{align}
                    x_i = \delta_0 + \delta_1 z_i + e_i 
                \end{align}
                and $\hat\pi_j$ are the \textit{reduced form} coefficients,
                \begin{align}
                    y_i = \pi_0 + \pi_1 z_i + \nu_i
                \end{align}
            \end{definition}
            
            This is equivalent to the IV estimator defined above as
            \begin{align}
                \hat\beta_1^\mathrm{Wald} = \frac{\frac{\ecov{z,y}}{\evar{z}}}{\frac{\ecov{z,x}}{\evar{z_i}}} = \hat\beta^\mathrm{IV}
            \end{align}

        
    \section{Two Stage Least Squares (2SLS)}
    
        IV allows us to overcome selection bias due to endogeneity. 2SLS allows us to generalise IV to binary, count or continuous variables and augment the equation with controls. In addition we can leverage multiple instruments to improve our estimates.

        \subsection{Motivation}
            Let $x$ be our explanatory variable, $y$ is the outcome variable and $z$ is a valid instrument. A baseline regression model would be
            \begin{align}
                y_i = \beta_0 + \beta_1 x_i + u_i
            \end{align}
            However we know that exogeneity fails for $x$, thus OLS is inconsistent and biased.
            
            Recall with \textit{IV/Wald estimators}, we can overcome this by estimating two equations: `First Stage' and `Reduced Form' models
            \begin{align}
                FS:\quad x_i &= \delta_0 + \delta_1 z_i + e_i\\
                RF:\quad y_i &= \pi_0 + \pi_1 z_i + v_i
            \end{align}
            We then compute the ratio as defined in Definition \ref{def:endogeneity/Wald}.

            \textbf{For 2SLS, we proceed as follows.} 
            \begin{enumerate}
                \item First estimate the first stage
                \begin{align}
                    FS:\quad x_i &= \delta_0 + \delta_1 z_i + e_i
                \end{align}
                and obtain predicted values $\hat x_i = \hat\delta_0 + \hat\delta_1 z_i$.
                
                \item Next, we regress $y_i$ on the predicted value of $x_i$, $\hat x_i$,
                \begin{align}
                    y_i = \beta_0^\mathrm{2SLS} + \beta_1^\mathrm{2SLS} \hat x_i + \varepsilon_i
                \end{align}
            \end{enumerate}


        \subsection{Implementation}
            
            \begin{sexylisting}[colback=white, label=lst:endogeneity/2SLS/implement]{2SLS estimation}
//  Run 2SLS regression (robust): 
//  Syntax: outcome control (endog.vars = instruments), robust
ivregress 2sls y w (x_1 x_2 = z_1 z_2 z_3), robust
            \end{sexylisting}
            \noindent It is important to note we \textit{cannot} do:\\ \\
            \indent\verb|reg x_1 z_1 z_2 z_3 w|    \\
            \indent\verb|predict x_1hat|   \\
            \indent\verb|reg x_2 z_1 z_2 z_3 w|    \\
            \indent\verb|predict x_2hat|   \\
            \indent\verb|reg y x_1hat x_2hat w, robust|\\ \\
            This is because when estimating standard error, STATA computes $\hat u_i$ with $\hat x_{j,i}$ instead of $x_{j,i}$ as defined below:
            \begin{align}
                \hat u_i = y_i - \left(\hat\beta_0^\mathrm{2SLS}+\hat\beta_1^\mathrm{2SLS} x_{1,i}+\hat\beta_2^\mathrm{2SLS}  x_{2,i}+\hat\beta_3^\mathrm{2SLS} w_i\right)
            \end{align}
            
        
    \section{Simultaneous Equation Models (SEM)}

        When we investigate demand and supply, we have two simultaneous equations that determine equilibrium quantity and price.
        
        \subsection{Motivation}
            Since we can only observe the black dots where equilibrium occurs, a regression would lead to a misunderstanding of the model, predicted by the black line. Instead what we want to know are the green and red lines, supply and demand equations.

            \begin{figure}
                \centering
                \input{figures/sem}
                \caption{Simultaneity bias}
                \label{fig:endogeneity/sem}
            \end{figure}

            Now suppose we have the model, or structural equations:
            \begin{align}
                &q_i =\beta_0^{(d)}+\beta_1^{(d)}p_i+e_i^{(d)}\\
                &q_i =\beta_0^{(s)}+\beta_1^{(s)}p_i+e_i^{(s)}
            \end{align}
            We would like to be able to hold one curve constant, while shifting the other, which would allow use to estimate the former, as shown on Figure X. Therefore we need a instrument that will shift one curve and allow us to estimate the other. Let this instrument be denoted $z$, and so our model becomes:
            \begin{align}
                &q_i =\beta_0^{(d)} + \beta_1^{(d)}p_i + e_i^{(d)}\label{eq:endogeneity/demand}\\
                &q_i =\beta_0^{(s)} + \beta_1^{(s)}p_i + \beta_2^{(s)}z^{(s)}_i + e_i^{(s)}\label{eq:endogeneity/supply_w_IV}
            \end{align}
            What properties does this instrument need to satisfy? We assume
            \begin{enumerate}
                \item \textbf{the instrument shifts the curve (i.e. supply curve)} - our relevance condition:
                \begin{align}
                    \cov{z^{(s)}, p} \neq 0
                \end{align}
                
                \item \textbf{the instrument does not move the other curve (i.e. demand curve)} - our exogeneity condition:
                \begin{align}
                    \cov{z^{(s)},e^{(d)}} = 0
                \end{align}
                
                \item \textbf{the instrument does not does not directly affect demand}, only affecting quantity through shifting supply - our exclusion condition.
            \end{enumerate}
            \begin{figure}
                \centering
                \input{figures/sem_iv}
                \caption{Instrument shifting supply curve}
                \label{fig:endogeneity/sem/iv}
            \end{figure}
            

        \subsection{IV estimation}
            Since we have established that  is an instrumental variable, we can estimate  with IV. Recall the definition of the IV estimator:
            \begin{align}
                \hat\beta^{(s),IV}_1 = \frac{\ecov{z^{(s)},q}}{\ecov{z^{(s)},p}}
            \end{align}
            We can implement this in STATA by performing the 2SLS method,
            \begin{itemize}
                \item \textbf{First stage.} Estimate the regression
                \begin{align}
                    p_i = \pi_0 + \pi_1 z_i^{(s)} + e_i
                \end{align}
                and obtaining the estimate $\hat p_i = \hat\pi_0 + \hat\pi_1 z_i^{(s)}$.

                \item \textbf{Second stage.} Estimate the regression
                \begin{align}
                    q_i = \beta_0^{(d)} + \beta_1^{(d)} \hat p_i + u_i^{(d)}
                \end{align}
            \end{itemize}
            
            To implement in STATA, refer to the code in Lising \ref{lst:endogeneity/SEM/2SLS}.
            \begin{sexylisting}[colback=white, label=lst:endogeneity/SEM/2SLS]{2SLS SEM estimation}
ivregress 2sls qty (price = supply_shift), robust
            \end{sexylisting}

            
        \subsection{Reduced form estimation}

            We know that in equilibrium, demand is equal to supply, therefore setting \eqref{eq:endogeneity/demand} equal to \eqref{eq:endogeneity/supply_w_IV}, by 
            \begin{itemize}
                \item \textbf{equating} $q_i$, we obtain
                \begin{align}
                    \beta_0^{(d)} + \beta_1^{(d)}p_i + e_i^{(d)} = \beta_0^{(s)} + \beta_1^{(s)}p_i + \beta_2^{(s)}z^{(s)}_i + e_i^{(s)}
                \end{align}
                which rearranges to yield
                \begin{align}
                    p_i = \pi_0 + \pi_1 z_i^{(s)} + e_i
                \end{align}
                where
                \begin{align}
                    \delta_0 := \frac{\beta_0^{(s)} - \beta_0^{(d)}}{\beta_1^{(d)} - \beta_1^{(s)}},\quad \delta_1 := \frac{\beta_2^{(s)} - \beta_0^{(d)}}{\beta_1^{(d)} - \beta_1^{(s)}},\quad e_i := \frac{u_i^{(s)}-u_i^{(d)}}{\beta_1^{(d)} - \beta_1^{(s)}}
                \end{align}

                \item \textbf{equating} $p_i$ (first rearranging \eqref{eq:endogeneity/demand} and \eqref{eq:endogeneity/supply_w_IV} for $p_i$), it can be shown that 
                \begin{align}
                    q_i = \pi_0 +\pi_1 z_i^{(s)} + v_i
                \end{align}
                where
                \begin{align}
                    \pi_0 := \beta_0^{(d)},\quad\pi_1 := \frac{\beta_1^{(d)}\beta_2^{(s)}}{\beta_1^{(d)} - \beta_1^{(s)}},\quad v_i = \frac{\beta_1^{(d)}u_i^{(s)} - \beta_1^{(s)}u_i^{(d)}}{\beta_1^{(d)} - \beta_1^{(s)}}
                \end{align}
            \end{itemize}
            Therefore, we note that the ratio of the coefficients gives $\beta_1^{(d)}$, more precisely,
            \begin{align}
                \beta_1^{(d)} = \frac{\pi_1}{\delta_1}
            \end{align}
            There we have it - if we estimate the two reduced form equations, then we can estimate the demand curve slope.
